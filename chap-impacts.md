Some Impacts of Data Abundance
-------------------------

*This chapter explores some impacts of big data deluge, tracks discussion and controversies from standpoints of science, business, and society. The possible role of (cartographic) visialisation in tackling these issues is also considered*

# Post-theory and hypothesis-less science?
# Correlation is enough?
# Ethic/Legal/... Remedies. Towards big data literacy (data-awareness)
# Data to Spatial to Visual (= cartography) for tackling complexity

## Science

-- data science, post theory

More on *value* -- the potential market value is potentially huge ("The potential value of Big Data is huge. Speaking about new Big Data initiatives in the US healthcare system last year, McKinsey estimated if these initiatives were rolled out system-wide, they “could account for $300 billion to $450 billion in reduced health-care spending, or 12 to 17 percent of the $2.6 trillion baseline in US health-care costs”. However, the cost of poor data is also huge- it’s estimated to cost US businesses $3.1 trillion a year. In essence, data on its own is virtually worthless. The value lies in rigorous analysis of accurate data, and the information and insights this provides." says @mcnulty2014understanding link on McKinsey <http://www.mckinsey.com/industries/healthcare-systems-and-services/our-insights/the-big-data-revolution-in-us-health-care>), but it "has the potential to cost unlimited amounts of money" @fischer2015why.


@anderson2008end: "where massive amounts of data and applied mathematics replace every other tool that might be brought to bear ... Who knows why people do what they do? The point is they do, and we can track it and measure it with unprecedented fidelity. With enough data, the numbers speak for themselves."


@wilson2017big: 
"In fact, the methods used to analyze large statistical data sets are themselves multiple, rather than singular. The type and context of the data govern the choices of the type of relevant analysis (for example, regression, significance testing, network analysis, frequency domain analysis, edge detection, decomposition, deconvolution, or machine learning using e.g., artificial neural nets). What is more, in traditional (regression) analyses, although algorithms can be written to extract patterns, the researcher or programmer constructing the algorithm must have imagined the pattern to be possible; and while advances in machine learning mean that algorithms can discover as well as illustrate patterns, the data on which they operate need to be understood in detail if spurious patterns are to avoided. In the following, we consider the case of automated analyses of electronic trace data left by students engaged in formal learning — so-called learning analytics — in an attempt to illustrate how the nature of data in a particular big data context, the intentions behind gathering and analyzing the data, and the appropriate analysis methods, all merit careful consideration."


## Business

-- where the hype (and bullshit comes form)
-- @marr2014big -- plenty of use cases from bussiness -- try to classify somehow? (not too much)

-- the question of maturity -- gartner's graph of technologies -- pozri diplomka (nejaká aktuálnejšia verzia?). -- search gartner hype cycle

## Society

-- some usual concerns
-- how to mitigate by lowering exhaustivity calling cognitive limits for the help

@florescu2012will -- posibility to extend official statistics with BD also kitchin2015opportunities

TODO -- use notes from file chap-philosophy of big data

## The improtance of visualization

-- vis for humans, machines do not need it (?) -- move to a different chapter
-- here just the societal responsibility of designers (first things first movement?, something for data visualists), and cartographers (harley, wood, crampton, -- radical cartography (Paglen?))

## more technical -- move somewhere else
* check later when you undestand it better :)
-- meta-data specifications for BD -- ask Radim & Tomas
-- ogc standard? -- refreshable wms? :P

NB https://www.theguardian.com/news/datablog/2008/jul/16/data-plural-singular

## risks

-- abuse at amazon -- @head2014worse
-- the world needs fixing, not disrupting: in <https://deardesignstudent.com/8-reasons-to-turn-down-that-startup-job-1f82a00ade34>
-- <https://medium.com/@freddiedeboer/the-three-hot-trends-in-silicon-valley-horseshit-95cc5a85e8a4>

## values

mayer2013big -- chapter value

examples: google flu trends:
ginsberg2009detecting
butler2013google -- critisism
cook2011assessing,
dugas2012google,

see also
@halevy2009unreasonable -- see video: https://www.youtube.com/watch?v=yvDCzhbjYWs

data creation in facilites:
-- cern obviously
-- https://www.lsst.org/ telescope in chile
-- companies providing acessing productivity in places like distribution centers @lewitt2016more
-- smart homes?

or more topic-based structure? from promise and peril
-----------------------------------------------------
-- How to Make Sense of Big Data?
     -- Data Correlation or Scientific Models?
     -- How Should Theories be Crafted in an Age of Big Data?
     -- Visualization as a Sense-Making Tool
     -- Bias-Free Interpretation of Big Data?
     -- Is More Actually Less?
     -- Correlations, Causality and Strategic Decision-making
-- How Should Big Data Abuses be Addressed?
     --Regulation, Contracts or Other Approaches?


from presentations at information+ 2016
----------

Catherine D’Ignazio 

Creative Data Literacy: Bridging the Gap Between the Data Haves and Have-nots

Communities are swimming in data—demographic data, participation data, government data, social media data—but very few understand what to do with it. Though governments and foundations are creating open data portals and corporations are creating APIs, these rarely focus on use, usability, building community or creating impact. So although there is an explosion of data, there is a significant lag in data literacy at the scale of communities and individuals. This creates a situation of data-haves and have-nots. But there are emerging technocultural practices that combine participation, creativity, and context to connect data to everyday life. These include citizen science, data journalism, novel public engagement in government processes, and participatory data art. This talk surveys these practices both lovingly and critically, including their premises, aspirations and the challenges to creating citizens that are truly empowered with data.

Yanni Loukissas

Local Data: Learning to Look at Big Data as Aggregates

Data are local: made by people and their dutiful machines, at a time, in a place, with the instruments at hand, using limited resources, to reach disciplined audiences. Although they are reliably transferred across digital communication networks, everywhere data remain marked by local artifacts: traces of the conditions and values that are particular to their origins. Even big data—a term that valorizes the scale and perceived autonomy of today’s data practices—are no more than aggregations of local knowledge, grounded in and inseparable from their social and material beginnings. This paper argues that we should learn to look at big data as data aggregates: collections of local data with varied and discordant infrastructural ties. In other words, if we are to fully understand the opportunities and pitfalls of big data, we must begin to see both the forest and the trees. 


----

*we are as good as we can measure* -- tabula pred cernom citacia

---
@lupton2015managing -- self-tracking and quantified self

--- 
právo a GDPR

---

@gandomi2015beyond – list of risks in bd-based predictive analytics: heterogenity, noise accumulation, spurious correlations, incidental endogeneity  -- Beyond the hype: Big data 
concepts, methods, and analytics

------------

@baldassarre2016think -- simple overall desc, good expl of **data science**

--------------

@wilson2017big: 

"In this paper, we have used three comparisons to draw out ways in which a particular and currently popular use of big data — learning analytics — differs from other big data contexts. We have tried to highlight the lessons for learning analytics that emerge from such explicit comparisons.

    First, the comparison with big data in the physical sciences highlighted the difference between intentional and incidental data collection; the need for robust theoretical underpinnings to measurements that rely on proxies rather than direct observation; the further need for robust theoretical underpinnings to explain or predict the presence and absence of correlations between different variables; and the dangers of comparing the infinitely differentiated interactions between students and learning resources with the endlessly repeatable interactions between fundamentally identical particles.

    Second, the comparison with big data in business intelligence highlighted the ethical issues around collecting data when users have no choice to opt out and do not give explicit or informed consent; issues around who business intelligence algorithms such as recommender systems are intended to benefit; the question of whether recommender systems are reliable (and if they are not, might they end up recommending behavior that is in fact detrimental to students); and questions of whether the digital trace data used in Learning Analytics are actually traces of learning at all.

    Third, the comparison with big data in public health highlighted the possible elision between the levels of population and individual; and the question of whether analytics are best used to change the behavior of consumers (students) or the conditions in which they find themselves.

-----------

(see @jagadish2015big, also for debunking some common myths about big data).

-----

my dogfood:

To those with resources, technical facilities (that emerged in recent years) allow storing data for future reuse even thought the utilization may be unclear at the moment of storing. There is an underlying hope that we can make sense of those data in the future. Data holders seek ways to monetize the information. BD are an attribute of interconnected society where individuals using ubiquitous technologies (web services, and mobile devices) create bigger and bigger digital footprints.

----------
@press2014big

some definitions:

(11) The belief that the more data you have the more insights and answers will rise automatically from the pool of ones and zeros.

(12) A new attitude by businesses, non-profits, government agencies, and individuals that combining data from multiple sources could lead to better decisions.

I like the last two. #11 is a warning against blindly collecting more data for the sake of collecting more data (see NSA). #12 is an acknowledgment that storing data in “data silos” has been the key obstacle to getting the data to work for us, to improve our work and lives. It’s all about attitude, not technologies or quantities.


-----
@diehm2018weaponised

on weaponized design

Weaponised design – a process that allows for harm of users within the defined bounds of a designed system – is faciliated by designers who are oblivious to the politics of digital infrastructure or consider their design practice output to be apolitical.

This is weaponised design: electronic systems whose designs either do not account for abusive application or whose user experiences directly empower attackers.

As platforms became more commodified – especially through mobile touch mediums – UX designers have progressively become more reliant on existing work, creating a feedback loop that promotes playfulness, obviousness and assumed trust at the expense of user safety.

A user story is “a very high-level definition of a requirement, containing just enough information so that the developers can produce a reasonable estimate of the effort to implement it". (definition from @ambler2014user)

When designing for the digital world, user stories ultimately determine what is or is not an acceptable area of human variation. The practice empowers designers and engineers to communicate via a common problem-focused language. But practicing design that views users through a politically-naive lens leaves practitioners blind to the potential weaponisation of their design. User-storied design abstracts an individual user from a person of lived experience to a collection of designer-defined generalisations. 

All intentionally-created systems have a set of things the designers consider part of the scope of what the system manages, but any nontrivial system has a broader set of impacts. Often, emergence takes the form of externalities — changes that impact people or domains beyond the designed scope of the system. @henriksenin2016frastructural 

Through inclusion, participatory design extends a design team’s focus beyond the hypothetical or ideal user, considering the interactions between users and other stakeholders over user stories.

In particular, security research and user experience design have significant practice and goal overlap and this relationship is often antagonistic. Both fields primarily focus on the systems of wide-scale interactions between users and technology, but the goals of the two fields are diametrically opposed; design is to create the best possible experience for a user, security is to create the worst possible experience for an attacker.



Geo specific speculations
--------------------------

2 fold, cartography and geoinformatics

GIS and cartography (partners in crime) facing big data -- Each with a different Sets of Challenges.

# Cartography

Sum up the manifesto here

Cognitive side, human perceptual responses... (not to overstate as I don't do it in this work). 

Ford's quote: "If I asked people what they want, they would ask for a faster horse" (find exact.). Similarly, we can test the cognitive efficiency of the visualisation methods that already exist, and users would prefer the methods they know. Cartography's quest (in my opinion) is to extend the arsenal of visualisation methods. As we will see further, interaction and animation pose new challenges to cartographic visualisation, with possibly multiplied opportunities for method combinations and innovations for data exploration and possibly knowledge generation. Further, plenty of tricks from the rich history of cartographic practice did not make it to web mapping toolbox. Recent emerging technology owing much to the gaming industry promise to bring web cartography to the flexibility of the pen and paper ^[or brush, engraving tool etc.] of pre-digital cartographer. Only now the shifted role of cartographer would be in enabling data to paint the picture for us.  Much of the rest of this thesis will be exploring this truly exciting prospect.

# GIS

Not within the scope of the thesis (and within author's powers) to consider all directions and areas where geoinformation science may be impacted by big data. 

GIT has a solid foundation of data-related concepts to build on. We shouldn't expect that the ideas like  (vector data model, spatial autocorellation, etc. list more properly) could be discarded by the fact that lots of data will be coming in faster to geoinformation systems. 

However, existing concepts should be (as a first step reviewed) in the light of new requirements. 

Review of the cannon of proved gis algorithms (see @xiao2015gis) in terms of scalability, how they deal with increased data load, is there a potential work in real time. TODO -- look at the algorithm complexity theory, could this be done for gis algorithms.

Trends, possibly trading off speed for precision, (e.g. the approximate db queries...). Maybe some trends of integrating with hadoop, spark, scala, kafka... etc.

Role of a data integrator with space as a unique integrating concept. 

GIS data aggergation venture -- addning indexicallity by spatialization

Spatialization .. ad hoc addition of spatial parametes to data. Real time possibilities of geocoding services? (how they actually work)

GIS project to be rethinked again, but proved itself to be capable of adopting new stuff and evolving with it.


@jiang2017spatial
-----------------

from toc:
- What is spatial Big Data
- Spaial and spatiotemporal BD Science


@li2016geospatial
-----------------
- challenges in big data

shekhar2014benchmarking
------------------------
- performance tests? -- proposed potential metrics

gis algorithms review:
--------------------
voronoi - @sharifzadeh2009approximate


temporal gis
------------
TODO research

some cartograms?
----------------

absolute vs relative views of space and time -- useful?
----
from andrienko:
The possibility of treating space and time both as referrers and as attrib-
utes is reflected in the reasoning concerning the absolute and relative
views of space and time (Peuquet 1994, 2002, Chrisman 1997). According
to the absolute view, space and time exist independently of objects and
form a framework, or a container, where objects are placed. According to
the relative view, both space and time are properties attached to objects
such as roads, rivers, and census tracts.

^
peuquet1994s
peuquet2002representations
peuquet2008multi
