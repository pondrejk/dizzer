# 6 Discussion and conclusions

This chapter provides a general discussion of results that complements the evaluation of case studies from Sections 4.5 and 5.5, as well as the precursory discussions from Sections 1.4 and 2.4. A general conclusion is also presented.

We stated that the combination of vector tiles and a WebGL-based rendering environment is an adequate solution for cartographic visualization of big data. The two applications described in Chapters 4 and 5 aim to support this statement. But it can be argued that the *real time* property of big data is not expressed too well in these case studies. This is partly due to the limited availability of continuous sources for our problem area. Also, the focus of the thesis is more on the cartographic solutions rather than on building complex back-end infrastructures for real-time data processing.

That being said, we can add that for big data sources that change in real time, vector tiles may seem as a bit inflexible solution. Once a tile set is generated, there are limited options to extend or alter the spatial definition of its features. Client libraries can filter features, apply styles, and also perform client-side data joins with external tabular data sources. But to accommodate fast-paced changes in the spatial definition of data, the data processing pipeline has to regenerate the tile set anew. 

On the other hand, having a continuously updated data source would not mean a significant difference when it comes to cartographic visualisation or UI design of the presented applications. For the first application (Chapter 4), the historical comparison is not that important to its purpose, so only the most up-to-date picture would be displayed. The second case (Chapter 5) study would need to incorporate the real time changes mainly to its comparison and selection controls.

We have already mentioned the lack of mature standardized tools for creation, serving, rendering and styling vector tiles. Currently we have a tight coupling of tile schemas with style definitions, which are not transferable across client libraries. Even though WebGL/OpenGL is an unifying concept that connects the libraries, writing GLSL code is challenging and not all libraries expose it directly. Some standardization in schemas and style definition languages, together with cross-operational tools are therefore vital for the future adoption of vector tiles.  

The original intent of vector tiles was presentational—to show intricate base maps efficiently across zoom levels. Analytical usage of the format may be complicated by some of its characteristics (e.g. the need to reconstruct geometries spreading across several tiles). But there is a great promise in vector tile schemas defined with spatial analysis in mind—it would enable client libraries to perform GIS-like operations in browser across various types of devices, or perform real-time analysis based on changing non-spatial attributes.

As we have seen in both case studies, tile size limitations have a profound impact on the final digital map, be it in length of achievable zoom range or in smoothness of user experience. Currently the limitations can be worked around by slicing the tile layers in various ways, or by applying some simplification functions on geometries, though there are no standard solutions for attribute compression and decoding on client. As we have suggested in Chapter 5, finding options for attribute compression in specific cases like time series encoding is another promising research area for vector tiles.

With the ability to store attributes of layers, vector tiles could redefine how we use base maps. For example, a road network layer can synthesize thematic information to be used for various purposes on client. This could include traffic speeds, taxi activity or sidewalk quality for navigation purposes (see project *SharedStreets*^[<https://sharedstreets.io>]), or all kinds of population and environmental data for urban planning purposes (ventures like *Remix*^[<https://www.remix.com/>], or *Morphcode*^[<https://morphocode.com/>]). As we have indicated in Chapter 4, keeping such layers up to date while allowing historical comparison is a true big data infrastructure problem. What is more, having both spatial and attribute information in one form that is efficiently downloadable for given area makes vector tiles a suitable input for spatially-enabled machine learning algorithms.

Furthermore, making tiles available through a server via controlled API is a viable option for both public and commercial data providers as it allows to differentiate citizen consumers from businesses. Some public map providers already started to adopt the technology (Ordinance Survey, swisstopo).

At this point, we can revisit the questions presented in Section 2.3.2. Learning about the capabilities of WebGL can help to shed some light on the first two questions (*Is cartography fully exploiting the digital medium?* and *What inspiration can digital cartography take from the heritage of pre-digital mapping?*). The presented case studies show to some degree what the WebGL-based rendering environment offers for thematic cartography. Note that these applications use just the subset of WebGL features made available by mapbox-gl. Stepping down at the level of individual shaders would allow to implement say the examples from Figure 26, and much more. Seeing how is WebGL utilized in gaming industry, we can argue that cartography is not yet fully exploiting its potential. Though this is a promise with a grain of salt, as writing GLSL code is not something cartographers usually have on their CVs—though it might be an exciting path for some to get on. When it comes to the question of deriving inspiration from non-digital maps, we argue that WebGL-based client libraries offer greater freedom to experiment with non-obvious symbolization (e.g. Figure 29 or Figure 33) than the previous generation of mapping libraries (using SVG over raster tiles).

Arriving at the third question from section 2.3.2 (*Should cartography focus more on interaction design?*), we expect that designing interactions with digital maps will become a common part of cartographic practice. Reading a map and controlling it via UI will be increasingly understood as two sides of the same coin. For many digital maps, the richness of possible interactions and the range of possible filtering outcomes are beyond the typical UX design schemes (user personas, scenarios, etc.), yet some of the UX principles are universally applicable (like clear visibility of system status or recovery from mistakes [@nielsen2005ten]) and digital cartographers would benefit from knowing them. As we have described in section 4.2, the features of the React library make it well applicable for creating map interfaces. Moreover, there is a room for developing a set of reusable map-specific components that cannot be found in mainstream component libraries (like *Bootstrap*, or *Material Design*). In general, creating digital maps is in many aspects different form bread-and-butter web development, with specific requirements in areas like data mocking or automated UI testing.

As we hope to have shown with both theoretical and practical arguments in this thesis, WebGL is currently the most promising platform for connecting cartographic excellence, dynamic spatial data visualization and user-friendly interaction. What remains is investing more effort into the capability of vector tiles to accommodate big data sources and into some standardization of technologies. This would paint a bright picture for the future of our field: transferability of cartographic work across rendering contexts would allow maps to break out from the desktop/mobile environments towards greater use in all kinds of future embedded devices.

Nothing suggests that the pace of data generation should get any less intense in the following years. Big data and the related technologies will become increasingly powerful forces in our society. Likewise, the spatial information will become available for analysis and visualisation in unprecedented amounts. While data and software can be used for bad and some negative impacts will surely start to unfold, we hope to have outlined some of the future paths for spatial fields to work toward the good.  

