# Philosophy of Big Data

@bollier2010promise
-------------------

-- John Seely Brown, Independent Co-Chair of Deloitte Center for the Edge, believes that we may need to devise new methods of theory formation: “One of the big problems [with Big Data] is how to determine if something is an outlier or not,” and therefore can be disregarded. “In some ways, the more data you have, the more basis you have for deciding that something is an outlier. You have more confidence in deciding what to knock out of the data set—at least, under the Bayesian and correlational-type theories of the moment.”
But this sort of theory-formation is fairly crude in light of the keen
and subtle insights that might be gleaned from Big Data, said Brown:
“Big Data suddenly changes the whole game of how you look at the
ethereal odd data sets.”  Instead of identifying outliers and “cleaning” datasets, theory formation using Big Data allows you to “craft an ontology and subject it to tests to see what its predictive value is.” “...The more data there is, the better my chances of finding the ‘generators’ for a new theory.”

-- “Financial markets are at least as complicated and important as the weather, but we don’t have the equivalent of a national weather service or a national hurricane center, for the financial markets.” John Liechty

-- "Large databases also open up all sorts of new business opportunities. **“Now-casting”** is helping companies understand the real-time dynamics of certain areas of life—from the diffusion of diseases to consumer purchases to night-life activity—which will have many long-term reverberations on markets. New types of **data-intermediaries** are also likely to arise to help people make sense of an otherwise-bewildering flood of information.  Indeed, data-intermediaries and interpreters could represent a burgeoning segment of the information technology sector in the years ahead."


siegfried2013big
-----------------
"...sometimes Big Data In means Bad Data Out. Wringing intelligent insights from Big Data poses formidable challenges for computer science, statistical inference methods and even the scientific method itself."

"Computer scientists, of course, have made the accumulation of all this big data possible by developing exceptional computing power and information storage technologies. But collecting data and storing information is not the same as understanding it. Figuring out what Big Data means isn’t the same as interpreting little data, just as understanding flocking behavior in birds doesn’t explain the squawks of a lone seagull."

"Many statistical procedures either have unknown runtimes or runtimes that render the procedure unusable on large-scale data,” writes Michael Jordan of the University of California, Berkeley. “Faced with this situation, gatherers of large-scale data are often forced to turn to ad hoc procedures that … may have poor or even disastrous statistical properties." -- <https://arxiv.org/abs/1309.7804>



"In particular, we emphasis on the viability of the sparsest solution in high-confidence set and point out that exogeneous assumptions in most statistical methods for Big Data can not be validated due to incidental endogeneity. They can lead to wrong statistical inferences and consequently wrong scientific conclusions."
"Besides that, Big Data often is acquired by combining information from many sources, at different times, using a variety of technologies or methodologies, Fan and colleagues point out. “This creates issues of heterogeneity, experimental variations, and statistical biases, and requires us to develop more adaptive and robust procedures,” they write. “To handle the challenges of Big Data, we need new statistical thinking and computational methods.”
<https://arxiv.org/abs/1308.1479> @fan2014challenges

"In fact, the arrival of Big Data should compel scientists to cope with the fact that nature itself is the ultimate Big Data database. Old style science coped with nature’s complexities by seeking the underlying simplicities in the sparse data acquired by experiments. But Big Data forces scientists to confront the entire repertoire of nature’s nuances and all their complexities."

... science cannot rely on the strictly empirical approach to answer questions about complex systems. There are too many possible factors influencing the system and too many possible responses that the system might make in any given set of circumstances. To use Big Data effectively, science might just have to learn to subordinate experiment to theory.




some notes from Massey -- For Space
-------------------------------------

3 common ways of thinking about space:
-- space as a surface we are placed on
-- turning space into time (space as slice through time)
-- sharp separation of local place and the world out there

^ those are failures of spatial immaginations

Her propositions
-- space is a prodct of interrelations, constituted through interactions
-- space is a condition for multiplicity, in space different trajectories coexist, space is predicated upon the existence of plurality
-- space is always under construction, never finished, never closed, it is a "simultaneity of stories so far"

Representation fixes (and deadens) time but also space, space is same as time unrepresentable in complete mimetic sense. Representation can be thought of as *spatialization* of the represented but can not be mistaken for the space itself (So beware of "spatial" metaphores that are used so automatically in present language).

Fabian 83 -- time and the other: "...a taxonomic space, indeed a map".

...not only might we productively conceptualise space in terms of relations but also relations can only be fully recognised by thinking fully spatially. In order for there to be relations there must of necessity be spacing.

-- space as a sphere of coexisitng multiplicity
-- ...maps (current Western-type maps) give the impression that space is a surface -- that it is the sphere of completed horizontality.
-- space -- not a discrete multiplicity of iner thins, rather heterogenity of practices and processes
-- everything in space has it's own temporality (history) (btw would be nice to be able to display it on a map, sort of a thermal image showing age instead of temperature). History had is own geographies too, so time and space are not contradictory, they are interrelated.
-- "everyting is connected to everything else" -- good reminder that our actions have wider implications, but unhelpful if it leads to a conception of already consituted holism (similar to what map shows). Space is potential links and connections yet to be made, loose ends and ongoing stories. "Loose ends and ongoing stories are real challenges to cartography".
-- Huggan 89 Decolonising the map... -- maps "exemplary structuralist activity"
-- maps are conceptual and a-temporal -- but ironically, given that these are maps, they are not spatial --structures

-- Rabasa 93 -- Inventing america..: The Atlas thus consitutes a world where all possible surprises have been precodified. ...As such tha Atlas is palimpsest (a complex palimpsest of allegories). -- about Mercator Atlas
-- on map ...We don not feel the disruptions of space, the coming upon diffence. On the road map you won't drive of the edge of your known world. In space, as I want to imagine it, you just might.


mayer2013big
-------------

NOW

-- Analogy: many images fast make a movie. "A movie is fundametally different from a frozen photograph. It's the same with big data: by changing the amount, we change the essence."

-- "Sometimes the constraints that we lice with, and persume, are the same for everything, are really only functions of the scale in which we operate." -- e.g. the main operting law of physics for us is gravity, for insects surface tension. Or nanotechonlogy -- at scale small enoug phyiscal properties change.
